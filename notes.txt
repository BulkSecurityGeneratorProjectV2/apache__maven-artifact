Maven Artifact is supposed to be a general artifact mechanism for retrieving, installing, and deploying artifacts
to repositories. Maven Artifact was originally decoupled from Maven proper and as such carries a lot of baggage
which prevents it from being used generally and carries many notions that are very specific to Maven itself. Artifacts
currently have a notion of scope, classifiers, and behavioral attributes such as whether scopes should be inherited.
For any mechanism to work generally these baked in notions need to be removed, vetted, and then made compatible with
notions currently in Maven. A list of things that should not be in the Artifact:

 * scope
 * classifier
 * dependency filter
 * dependency trail
 * resolved
 * released
 * optional
 * available versions

These are all attributes of the target system

*Removal of the ArtifactFactory
        
 3 February 2008 (Sunday)

 I have removed the factory and left only a small set of constructors (which I would like to reduce to one) so that you
 have a valid artifact after construction. I have also started to hide the VersionRange creation. You just pass in
 a string and the constructor for the DefaultArtifact will do the right thing. This will ultimately need to be more
 pluggable as different versioning strategies happen. But variations of the theme like Maven, OSGi, will have their
 own subclasses and tools to operate on the graphs of dependencies.

 4 February 2008 (Monday)

 John:
 Some notes about classifiers taken from the mailing list in a discussion with John about classifiers:
 I'd tend to disagree about classifier not being a 'core' part of the artifact system...it distinguishes a main
 artifact from one of its derivatives, and serves as a pretty foundational part of how we retrieve artifacts from existing
 remote repositories. Without it, I doubt that you can reconstruct the path to some existing artifacts (like sources or javadocs)
 reliably without bastardizing the version string.

 We can see that the artifact system has certain inescapable identity attributes. Scope is obviously more related
 to how an artifact is used, since you can't see any trace of scope in the artifact as it's been deployed on a remote
 repository. Classifier, however, doesn't fit this criteria...it's not a usage marker, but an identity marker.

 The rest I agree with.

 Jason:
 This is where I think you've already baked in what you think about Maven. Look at how we deploy our derivative
 artifacts right now. We don't track any of it in the metadata when we deploy. We toss it up there and things hope
 they are there. Like javadocs, or sources. I think what's more important is that the coordinate be unique and we
 have a way to associate what ever artifacts together in a scalable way. So you say "I want to associate this artifact
 with that one, this is how I would like to record that relationship in the metadata.". Subsequently you can query
 the metadata and know these relationships. We currently don't do this. It generally boils down to a bunch of
 coordinates in the repository. How we choose to relate them via the metadata. We have all sort of problems with
 classifiers currently because it was an adhoc method of association. A general model of association would be a
 superset of what we currently do for classifiers. I agree we need an mechanism for association, I don't think
 classifiers have worked all that well.

 5 February 2008 (Tuesday)

 The rework of the artifact resolution mechanism is an attempt to entirely separate 1) the process of metadata retrieval into
 a tree, 2) converting the tree to a graph by a process of conflict resolution, and 3) retrieving the complete set
 of artifacts, and ultimately 4) Doing something in a particular fashion withe the retrieved set like make a classpath.
 Currently we have an incremental processing model that doesn't let a complete graph be formed for analysis
 which greatly complicates the process whereas having a graph and using standard graph analysis techniques and graph
 optimization is the only reasonable way forward. There should be no doubt about what needs to be retrieved once the
 analysis is complete. We could actually create an aggregrate request where instructions are sent to retrieve everything
 required. The server could send a stream all the artifacts back in one shot.

 What Oleg is attempting to do is create a working solution for 1) and 2) above. Along with the implementation we also
 have a visualization tool that will help us determine what exactly the correct analysis is. The beauty of this is that
 regardless of the analysis we arrive at a representation of the complete set can be modeled and we can start working on
 the optimized retrieval mechanism. We still need to do some work to separate out 4) as we're doing some classpath
 calculations already which we will need to further decouple but that should be relatively straight forward.

                
